{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import pyautogui\n",
    "import numpy as np\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m  \u001b[38;5;66;03m# 스크린 전체를 캡처합니다.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m screenshot \u001b[38;5;241m=\u001b[39m ImageGrab\u001b[38;5;241m.\u001b[39mgrab()\n\u001b[1;32m---> 20\u001b[0m cropped_image \u001b[38;5;241m=\u001b[39m screenshot\u001b[38;5;241m.\u001b[39mcrop((\u001b[43mstart_x\u001b[49m, start_y, stop_x, stop_y))\n\u001b[0;32m     21\u001b[0m screenshot \u001b[38;5;241m=\u001b[39m ImageGrab\u001b[38;5;241m.\u001b[39mgrab()\n\u001b[0;32m     22\u001b[0m cropped_image \u001b[38;5;241m=\u001b[39m screenshot\u001b[38;5;241m.\u001b[39mcrop((start_x, start_y, stop_x, stop_y))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'start_x' is not defined"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "import time\n",
    "from PIL import ImageGrab\n",
    "import keyboard\n",
    "\n",
    "def on_key_press(event):\n",
    "    if event.name == 'q':\n",
    "        start_x, start_y = pyautogui.position()\n",
    "        print(\"Q 키를 눌렀을 때 마우스 좌표:\", start_x, start_y)\n",
    "        time.sleep(0.3)\n",
    "    elif event.name == 'w':\n",
    "        stop_x, stop_y = pyautogui.position()\n",
    "        print(\"W 키를 눌렀을 때 마우스 좌표:\", stop_x, stop_y)\n",
    "        time.sleep(0.3)\n",
    "\n",
    "keyboard.on_press(on_key_press)\n",
    "keyboard.wait('esc') \n",
    " # 스크린 전체를 캡처합니다.\n",
    "screenshot = ImageGrab.grab()\n",
    "cropped_image = screenshot.crop((start_x, start_y, stop_x, stop_y))\n",
    "screenshot = ImageGrab.grab()\n",
    "cropped_image = screenshot.crop((start_x, start_y, stop_x, stop_y))\n",
    "# 잘라낸 영역 저장\n",
    "cropped_image.save(\"cropped_screenshot1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Image' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 38\u001b[0m\n\u001b[0;32m     32\u001b[0m     text1 \u001b[38;5;241m=\u001b[39m pytesseract\u001b[38;5;241m.\u001b[39mimage_to_string(cropped_image)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(text1)\n\u001b[1;32m---> 38\u001b[0m \u001b[43mcount_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m keyboard\u001b[38;5;241m.\u001b[39mon_press(on_key_press)\n",
      "Cell \u001b[1;32mIn[33], line 31\u001b[0m, in \u001b[0;36mcount_keys\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m screenshot \u001b[38;5;241m=\u001b[39m ImageGrab\u001b[38;5;241m.\u001b[39mgrab()\n\u001b[0;32m     30\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m cropped_image \u001b[38;5;241m=\u001b[39m \u001b[43mscreenshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcrop((x, y, x1, y2))\n\u001b[0;32m     32\u001b[0m text1 \u001b[38;5;241m=\u001b[39m pytesseract\u001b[38;5;241m.\u001b[39mimage_to_string(cropped_image)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(text1)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Image' object is not callable"
     ]
    }
   ],
   "source": [
    "import keyboard\n",
    "from PIL import ImageGrab, Image\n",
    "from datetime import datetime\n",
    "import pyautogui\n",
    "import time\n",
    "import pytesseract\n",
    "\n",
    "x, y, x1, y2 = 0, 0, 0, 0\n",
    "count = 0\n",
    "# text1 = \"\"\n",
    "# text2 = \"\"\n",
    "\n",
    "def on_key_press(event):\n",
    "    global x, y, x1, y2, count\n",
    "    \n",
    "    if event.name == '1':\n",
    "        x, y = pyautogui.position()\n",
    "    elif event.name == '2':\n",
    "        x1, y2 = pyautogui.position()\n",
    "        count += 1\n",
    "\n",
    "keyboard.on_press(on_key_press)\n",
    "\n",
    "def count_keys():\n",
    "    global x, y, x1, y2, count\n",
    "    \n",
    "    keyboard.wait('esc')\n",
    "    \n",
    "    screenshot = ImageGrab.grab()\n",
    "    time.sleep(0.1)\n",
    "    cropped_image = screenshot().crop((x, y, x1, y2))\n",
    "    text1 = pytesseract.image_to_string(cropped_image)\n",
    "    print(text1)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "count_keys()\n",
    "keyboard.on_press(on_key_press)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyboard\n",
    "from PIL import ImageGrab, Image\n",
    "from datetime import datetime\n",
    "import pyautogui\n",
    "import time\n",
    "import pytesseract\n",
    "\n",
    "# Global variables to store coordinates and texts\n",
    "x, y, x1, y2 = 0, 0, 0, 0\n",
    "count = 0\n",
    "text1 = \"\"\n",
    "text2 = \"\"\n",
    "\n",
    "# Function to capture key presses and update coordinates\n",
    "def on_key_press(event):\n",
    "    global x, y, x1, y2, count\n",
    "    \n",
    "    if event.name == '1':\n",
    "        x, y = pyautogui.position()\n",
    "    elif event.name == '2':\n",
    "        x1, y2 = pyautogui.position()\n",
    "        count += 1\n",
    "\n",
    "keyboard.on_press(on_key_press)\n",
    "\n",
    "# Function to capture screenshots, extract text, and display unique characters\n",
    "def count_keys():\n",
    "    global x, y, x1, y2, count, text1, text2\n",
    "    \n",
    "    keyboard.wait('esc')\n",
    "    \n",
    "    screenshot = ImageGrab.grab()\n",
    "    time.sleep(0.1)\n",
    "    cropped_image = screenshot.crop((x, y, x1, y2))\n",
    "    if count == 1:\n",
    "        text1 = pytesseract.image_to_string(cropped_image)\n",
    "        print(f\"Text1: {text1}\")\n",
    "    elif count == 2:\n",
    "        text2 = pytesseract.image_to_string(cropped_image)\n",
    "        print(f\"Text2: {text2}\")\n",
    "\n",
    "        set1 = set(text1)\n",
    "        set2 = set(text2)\n",
    "        \n",
    "        unique_to_text1 = set1 - set2\n",
    "        unique_to_text2 = set2 - set1\n",
    "        \n",
    "        print(\"Unique characters in the first text:\")\n",
    "        print(''.join(unique_to_text1))\n",
    "        \n",
    "        print(\"Unique characters in the second text:\")\n",
    "        print(''.join(unique_to_text2))\n",
    "    \n",
    "    time.sleep(0.1)\n",
    "    # Optionally save the cropped image with a timestamp\n",
    "    # timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    # cropped_image.save(f\"cropped_screenshot_{timestamp}.jpg\")\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# Start capturing screenshots and extracting text\n",
    "count_keys()\n",
    "keyboard.on_press(on_key_press)\n",
    "count_keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press '1' to set the first corner.\n",
      "Press '2' to set the second corner.\n",
      "Press 'esc' to capture and process the region.\n",
      "Captured text:\n",
      "총 갯수  43\n",
      "# Run the count_keys function\n",
      "count_keys()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keyboard\n",
    "from PIL import ImageGrab\n",
    "import pyautogui\n",
    "import time\n",
    "import pytesseract\n",
    "\n",
    "# Initialize global variables\n",
    "x, y, x1, y2 = 0, 0, 0, 0\n",
    "count = 0\n",
    "\n",
    "def on_key_press(event):\n",
    "    global x, y, x1, y2, count\n",
    "    \n",
    "    if event.name == '1':\n",
    "        x, y = pyautogui.position()\n",
    "        print(f\"First corner set at: ({x}, {y})\")\n",
    "    elif event.name == '2':\n",
    "        x1, y2 = pyautogui.position()\n",
    "        print(f\"Second corner set at: ({x1}, {y2})\")\n",
    "        count += 1\n",
    "\n",
    "keyboard.on_press(on_key_press)\n",
    "\n",
    "def count_keys():\n",
    "    global x, y, x1, y2, count\n",
    "    \n",
    "    print(\"Press '1' to set the first corner.\")\n",
    "    print(\"Press '2' to set the second corner.\")\n",
    "    print(\"Press 'esc' to capture and process the region.\")\n",
    "    \n",
    "    keyboard.wait('esc')  # Wait until 'esc' is pressed to proceed\n",
    "    \n",
    "    if count > 0:\n",
    "        # Capture the screenshot of the specified region\n",
    "        screenshot = ImageGrab.grab(bbox=(x, y, x1, y2))\n",
    "        screenshot.show()\n",
    "        time.sleep(0.1)  # Small delay to ensure the screenshot is taken\n",
    "        \n",
    "        # Perform OCR on the cropped image\n",
    "        text1 = pytesseract.image_to_string(screenshot)\n",
    "        print(\"Captured text:\")\n",
    "        print('총 갯수 ',len(text1))        \n",
    "        print(text1)\n",
    "             \n",
    "    else:\n",
    "        print(\"Second corner not set, capture not performed.\")\n",
    "\n",
    "# Run the count_keys function\n",
    "count_keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press '1' to set the first corner.\n",
      "Press '2' to set the second corner.\n",
      "Press 'esc' to capture and process the region.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSecond corner not set, capture not performed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Run the count_keys function\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[43mcount_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[78], line 56\u001b[0m, in \u001b[0;36mcount_keys\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Preprocess the image\u001b[39;00m\n\u001b[0;32m     55\u001b[0m processed_image \u001b[38;5;241m=\u001b[39m preprocess_image(screenshot)\n\u001b[1;32m---> 56\u001b[0m \u001b[43mprocessed_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m()\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Perform OCR on the processed image\u001b[39;00m\n\u001b[0;32m     58\u001b[0m text1 \u001b[38;5;241m=\u001b[39m pytesseract\u001b[38;5;241m.\u001b[39mimage_to_string(processed_image)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "import keyboard\n",
    "from PIL import ImageGrab, Image\n",
    "import pyautogui\n",
    "import time\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyperclip\n",
    "\n",
    "# Initialize global variables\n",
    "x, y, x1, y2 = 0, 0, 0, 0\n",
    "count = 0\n",
    "\n",
    "def on_key_press(event):\n",
    "    global x, y, x1, y2, count\n",
    "    \n",
    "    if event.name == '1':\n",
    "        x, y = pyautogui.position()\n",
    "        print(f\"First corner set at: ({x}, {y})\")\n",
    "    elif event.name == '2':\n",
    "        x1, y2 = pyautogui.position()\n",
    "        print(f\"Second corner set at: ({x1}, {y2})\")\n",
    "        count += 1\n",
    "\n",
    "keyboard.on_press(on_key_press)\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply Otsu's thresholding\n",
    "    _, binary_image = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    return binary_image\n",
    "\n",
    "def count_keys():\n",
    "    global x, y, x1, y2, count\n",
    "    \n",
    "    print(\"Press '1' to set the first corner.\")\n",
    "    print(\"Press '2' to set the second corner.\")\n",
    "    print(\"Press 'esc' to capture and process the region.\")\n",
    "    \n",
    "    keyboard.wait('esc')  # Wait until 'esc' is pressed to proceed\n",
    "    \n",
    "    if count > 0:\n",
    "        # Capture the screenshot of the specified region\n",
    "        screenshot = ImageGrab.grab(bbox=(x, y, x1, y2))\n",
    "        screenshot.show()\n",
    "        screenshot = np.array(screenshot)  # Convert PIL image to numpy array\n",
    "        \n",
    "        # Preprocess the image\n",
    "        processed_image = preprocess_image(screenshot)\n",
    "        \n",
    "        # Perform OCR on the processed image\n",
    "        text1 = pytesseract.image_to_string(processed_image)\n",
    "        # print(\"Captured text:\", len(text1))\n",
    "        print(text1)\n",
    "        enter = text1.splitlines()\n",
    "        #print(enter)\n",
    "        joined_text = '\\t'.join(enter)\n",
    "        print(joined_text)\n",
    "        pyperclip.copy(joined_text)\n",
    "    else:\n",
    "        print(\"Second corner not set, capture not performed.\")\n",
    "\n",
    "# Run the count_keys function\n",
    "count_keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "enter = text1.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pytesseract pyautogui "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press '1' to set the first corner.\n",
      "Press '2' to set the second corner.\n",
      "Press 'esc' to capture and process the region.\n",
      "VDD(0]\n",
      "VDDf1]\n",
      "VDD[2]\n",
      "VDD{3}\n",
      "VDD{4]\n",
      "VDD{5]\n",
      "VDD{6]\n",
      "VDD{7]\n",
      "VDD{8}\n",
      "VDDI9}\n",
      "VDD[10]\n",
      "VDD[11]\n",
      "VDD[12]\n",
      "VDD[13]\n",
      "VDD[14]\n",
      "VDD[15]\n",
      "VDD[16]\n",
      "VDD[17]\n",
      "VDD[18]\n",
      "VDD[19]\n",
      "VDD[20}\n",
      "VDD[21]\n",
      "VDD[22]\n",
      "VDD[23}\n",
      "VDD[24]\n",
      "VDD[25]\n",
      "VDD[26]\n",
      "VDD[27]\n",
      "VDD[28}\n",
      "VDD[29]\n",
      "VDD[30}\n",
      "VDD{31]\n"
     ]
    }
   ],
   "source": [
    "import keyboard\n",
    "from PIL import ImageGrab, Image\n",
    "import pyautogui\n",
    "import time\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyperclip\n",
    "\n",
    "# Initialize global variables\n",
    "x, y, x1, y2 = 0, 0, 0, 0\n",
    "count = 0\n",
    "\n",
    "def on_key_press(event):\n",
    "    global x, y, x1, y2, count\n",
    "    \n",
    "    if event.name == '1':\n",
    "        x, y = pyautogui.position()\n",
    "        print(f\"First corner set at: ({x}, {y})\")\n",
    "    elif event.name == '2':\n",
    "        x1, y2 = pyautogui.position()\n",
    "        print(f\"Second corner set at: ({x1}, {y2})\")\n",
    "        count += 1\n",
    "\n",
    "keyboard.on_press(on_key_press)\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply Otsu's thresholding\n",
    "    _, binary_image = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    return binary_image\n",
    "\n",
    "def annotate_image(image, boxes):\n",
    "    for box in boxes:\n",
    "        x, y, w, h = box['left'], box['top'], box['width'], box['height']\n",
    "        # Draw rectangle around the detected text\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        # Put the recognized text above the rectangle\n",
    "        cv2.putText(image, box['text'], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "def count_keys():\n",
    "    global x, y, x1, y2, count\n",
    "    \n",
    "    print(\"Press '1' to set the first corner.\")\n",
    "    print(\"Press '2' to set the second corner.\")\n",
    "    print(\"Press 'esc' to capture and process the region.\")\n",
    "    \n",
    "    keyboard.wait('esc')  # Wait until 'esc' is pressed to proceed\n",
    "    \n",
    "    if count > 0:\n",
    "        # Capture the screenshot of the specified region\n",
    "        screenshot = ImageGrab.grab(bbox=(x, y, x1, y2))\n",
    "        screenshot.show()\n",
    "        screenshot = np.array(screenshot)  # Convert PIL image to numpy array\n",
    "        \n",
    "        # Preprocess the image\n",
    "        processed_image = preprocess_image(screenshot)\n",
    "        \n",
    "        # Perform OCR on the processed image\n",
    "        custom_config = r'--oem 3 --psm 6'\n",
    "        data = pytesseract.image_to_data(processed_image, config=custom_config, output_type=pytesseract.Output.DICT)\n",
    "        \n",
    "        n_boxes = len(data['level'])\n",
    "        boxes = []\n",
    "        for i in range(n_boxes):\n",
    "            if int(data['conf'][i]) > 60:  # Confidence threshold\n",
    "                (x, y, w, h) = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])\n",
    "                boxes.append({'left': x, 'top': y, 'width': w, 'height': h, 'text': data['text'][i]})\n",
    "\n",
    "        # Annotate image with detected text\n",
    "        annotate_image(screenshot, boxes)\n",
    "\n",
    "        # Convert the processed image back to a PIL image and show it\n",
    "        annotated_image = Image.fromarray(screenshot)\n",
    "        annotated_image.show()\n",
    "        \n",
    "        # Remove empty lines\n",
    "        text1 = pytesseract.image_to_string(processed_image, config=custom_config)\n",
    "        enter = [line for line in text1.splitlines() if line.strip() != '']\n",
    "        joined_text = '\\n'.join(enter)\n",
    "        print(joined_text)\n",
    "        pyperclip.copy(joined_text)\n",
    "        \n",
    "        # Show the processed image\n",
    "        Image.fromarray(processed_image).show()\n",
    "    else:\n",
    "        print(\"Second corner not set, capture not performed.\")\n",
    "\n",
    "# Run the count_keys function\n",
    "count_keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi \n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "import pyperclip\n",
    "\n",
    "# 클립보드의 내용을 읽어옵니다.\n",
    "hi = \"hi \\nhi\"\n",
    "pyperclip.copy(hi)\n",
    "clipboard_content = pyperclip.paste()\n",
    "\n",
    "# 클립보드 내용을 출력합니다.\n",
    "print(clipboard_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press '1' to set the first corner.\n",
      "Press '2' to set the second corner.\n",
      "Press '3' to capture and process the region.\n",
      "Press 'esc' to exit.\n"
     ]
    }
   ],
   "source": [
    "import keyboard\n",
    "from PIL import ImageGrab, Image\n",
    "import pyautogui\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyperclip\n",
    "\n",
    "# Initialize global variables\n",
    "x, y, x1, y2 = 0, 0, 0, 0\n",
    "count = 0\n",
    "\n",
    "def on_key_press(event):\n",
    "    global x, y, x1, y2, count\n",
    "    \n",
    "    if event.name == '1':\n",
    "        x, y = pyautogui.position()\n",
    "        print(f\"First corner set at: ({x}, {y})\")\n",
    "    elif event.name == '2':\n",
    "        x1, y2 = pyautogui.position()\n",
    "        print(f\"Second corner set at: ({x1}, {y2})\")\n",
    "        count += 1\n",
    "    elif event.name == '3':\n",
    "        capture_and_process()\n",
    "\n",
    "keyboard.on_press(on_key_press)\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply Otsu's thresholding\n",
    "    _, binary_image = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    return binary_image\n",
    "\n",
    "def annotate_image(image, boxes):\n",
    "    for box in boxes:\n",
    "        x, y, w, h = box['left'], box['top'], box['width'], box['height']\n",
    "        # Draw rectangle around the detected text\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        # Put the recognized text above the rectangle\n",
    "        cv2.putText(image, box['text'], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "def capture_and_process():\n",
    "    global x, y, x1, y2, count\n",
    "    \n",
    "    if count > 0:\n",
    "        # Capture the screenshot of the specified region\n",
    "        screenshot = ImageGrab.grab(bbox=(x, y, x1, y2))\n",
    "        screenshot = np.array(screenshot)  # Convert PIL image to numpy array\n",
    "        \n",
    "        # Preprocess the image\n",
    "        processed_image = preprocess_image(screenshot)\n",
    "        \n",
    "        # Perform OCR on the processed image\n",
    "        custom_config = r'--oem 3 --psm 6'\n",
    "        data = pytesseract.image_to_data(processed_image, config=custom_config, output_type=pytesseract.Output.DICT)\n",
    "        \n",
    "        n_boxes = len(data['level'])\n",
    "        boxes = []\n",
    "        for i in range(n_boxes):\n",
    "            if int(data['conf'][i]) > 60:  # Confidence threshold\n",
    "                (x, y, w, h) = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])\n",
    "                boxes.append({'left': x, 'top': y, 'width': w, 'height': h, 'text': data['text'][i]})\n",
    "\n",
    "        # Annotate image with detected text\n",
    "        annotate_image(screenshot, boxes)\n",
    "\n",
    "        # Convert the processed image back to a PIL image and show it\n",
    "        annotated_image = Image.fromarray(screenshot)\n",
    "        annotated_image.show()\n",
    "        \n",
    "        # Remove empty lines\n",
    "        text1 = pytesseract.image_to_string(processed_image, config=custom_config)\n",
    "        enter = [line for line in text1.splitlines() if line.strip() != '']\n",
    "        joined_text = '\\n'.join(enter)\n",
    "        print(joined_text)\n",
    "        pyperclip.copy(joined_text)\n",
    "        \n",
    "        # Show the processed image\n",
    "        Image.fromarray(processed_image).show()\n",
    "    else:\n",
    "        print(\"Second corner not set, capture not performed.\")\n",
    "\n",
    "def main():\n",
    "    print(\"Press '1' to set the first corner.\")\n",
    "    print(\"Press '2' to set the second corner.\")\n",
    "    print(\"Press '3' to capture and process the region.\")\n",
    "    print(\"Press 'esc' to exit.\")\n",
    "\n",
    "    keyboard.wait('esc')  # Wait until 'esc' is pressed to exit\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    x, y = pyautogui.position()\n",
    "    print('x = ', x, 'y = ' ,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
